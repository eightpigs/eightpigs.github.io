<head><meta charset=utf-8><meta name=generator content="Hugo 0.105.0"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=author content="Eightpigs, eightpigs@outlook.com"><meta property="og:url" content="https://eightpigs.io/2021/07/06/using_k3s/"><link rel=canonical href=https://eightpigs.io/2021/07/06/using_k3s/><link rel=stylesheet href="/css/github-markdown.css?t=1464395400000"><link rel=stylesheet href="/css/head.css?t=1464395400000"><link rel=stylesheet href="/css/style.css?t=1464395400000"><link rel=stylesheet href="/css/list.css?t=1464395400000"><title>K3s 上手 - 集群搭建 - Eightpigs</title><meta property="og:title" content="K3s 上手 - 集群搭建 - Eightpigs"><meta property="og:type" content="article"><meta property="og:description" content="在《PVE 中虚拟化万兆网卡》中我有提到自己攒了台双路的机器放在家里，长期以来作为我远程的 Power 机器，在上面用 Docker-Compose 跑我的各种服务。从攒好机器到现在，"><meta name=description content="在《PVE 中虚拟化万兆网卡》中我有提到自己攒了台双路的机器放在家里，长期以来作为我远程的 Power 机器，在上面用 Docker-Compose 跑我的各种服务。从攒好机器到现在，"><meta name=keywords content="IT,Java,Go,Web,Programmer,Algorithm,Runner"><link rel=stylesheet href=/css/highlight/github.css><link rel=stylesheet href="/css/post.css?t=1464395400000"></head><div class="content markdown-body"><h1>K3s 上手 - 集群搭建</h1><div class=info><span class=date>2021-07-06</span>
<span class=categories><a data-real=Infrastructure href=/categories/infrastructure/ class=category>基础设施</a>
⯈</span>
<span class=tags><a data-real=K3s href=/tags/k3s/ class=tag>#K3s</a>
<a data-real=K8s href=/tags/k8s/ class=tag>#K8s</a>
<a data-real=Kubernetes href=/tags/kubernetes/ class=tag>#Kubernetes</a>
<a data-real=Traefik href=/tags/traefik/ class=tag>#Traefik</a>
<a data-real=Homelab href=/tags/homelab/ class=tag>#Homelab</a>
<a data-real=Wireguard href=/tags/wireguard/ class=tag>#Wireguard</a></span></div></h1><p>在<a href=https://eightpigs.io/2021/07/05/pve_10g_nic/>《PVE 中虚拟化万兆网卡》</a>中我有提到自己攒了台双路的机器放在家里，长期以来作为我远程的 Power 机器，在上面用 Docker-Compose 跑我的各种服务。从攒好机器到现在，反复多次搭建 Kubernetes，最终都放弃了：<strong>上手成本的确高</strong>。</p><blockquote><p>是否要用 Kubernetes 取代 Docker-Compose ?</p></blockquote><p>从理性的角度来说，Docker-Compose 完全胜任，简单，好用，完全没必要。然而在 Kubernetes 大行其道的今天，感性方面告诉我一定要跟着大家上高端的 Kubernetes&mldr;</p><p>最近有又冒出了想用 Kubernetes 的想法，在几经犹豫之后，最终决定本次一定不能中途放弃！！！为了减少搭建复杂度和资源的占用，本次选择了<a href=https://k3s.io/>K3s</a>。</p><blockquote><p>The certified Kubernetes distribution built for IoT & Edge computing.</p></blockquote><p>K3s 是一个 Kubernetes 认证的发行版，可以理解为一个轻量级的 K8s，K3s 的架构如下:</p><p><img src=./how-it-works-k3s.svg alt="Hot it works - k3s"></p><h2 id=集群规划>集群规划</h2><p>集群规划有两点需要考虑：</p><ol><li><strong>是否要上HA</strong>：不需要，所有 VM 都通过 PVE 跑在一台物理机上，没必要上 HA。</li><li><strong>数据如何存储</strong>：各节点的所有数据均通过 NFS 存储到 NAS 中，每个节点仅提供操作系统必须的磁盘空间即可。</li></ol><p>我的规划中，共4个节点，每个节点相同配置：4C 8G，细节如下：</p><table><thead><tr><th style=text-align:center>HostName</th><th style=text-align:center>CPU</th><th style=text-align:center>Memory</th><th style=text-align:center>Disk</th><th style=text-align:center>OS</th><th style=text-align:center>IP</th></tr></thead><tbody><tr><td style=text-align:center>k3s-server</td><td style=text-align:center>4</td><td style=text-align:center>8G</td><td style=text-align:center>5G</td><td style=text-align:center>Debian 10 (5.10.40-1~bpo10+1)</td><td style=text-align:center>192.168.2.21</td></tr><tr><td style=text-align:center>k3s-worker-01</td><td style=text-align:center>4</td><td style=text-align:center>8G</td><td style=text-align:center>5G</td><td style=text-align:center>Debian 10 (5.10.40-1~bpo10+1)</td><td style=text-align:center>192.168.2.22</td></tr><tr><td style=text-align:center>k3s-worker-02</td><td style=text-align:center>4</td><td style=text-align:center>8G</td><td style=text-align:center>5G</td><td style=text-align:center>Debian 10 (5.10.40-1~bpo10+1)</td><td style=text-align:center>192.168.2.23</td></tr><tr><td style=text-align:center>k3s-worker-03</td><td style=text-align:center>4</td><td style=text-align:center>8G</td><td style=text-align:center>5G</td><td style=text-align:center>Debian 10 (5.10.40-1~bpo10+1)</td><td style=text-align:center>192.168.2.24</td></tr></tbody></table><h2 id=前期准备>前期准备</h2><h3 id=节点间互相访问>节点间互相访问</h3><p>以下为 k3s-server 的配置，其他 worker 节点同理，手动配置略麻烦，有兴趣的可以使用 ansible 批量操作。</p><pre><code class=language-shell>k3s-server # cat /etc/hosts
...
192.168.2.6     nas             # 我自建的NAS
192.168.2.22    k3s-worker-01
192.168.2.23    k3s-worker-02
192.168.2.24    k3s-worker-03
...
</code></pre><h3 id=能顺畅访问-docker-hub-gcrio-k8s-gcrio>能顺畅访问 docker-hub, gcr.io, k8s-gcr.io</h3><p>网络问题真的令人头疼，虽然 K3s 跑起来很简单，但避免不了后续需要从以上几个 Registry 中拉取镜像，所以建议第一步先
自建一个统一的代理，可以使用我整理的一键安装脚本，详见: <a href=https://github.com/eightpigs/proxy_registry_k3s>registry on k3s</a></p><p>以下为该安装脚本的使用步骤：</p><blockquote><ol><li><p>拥有一台可以访问 gcr.io, k8s-gcr.io&mldr; 并且有公网 IP 的机器</p></li><li><p>在机器上拉取本仓库: <code>git clone https://github.com/eightpigs/proxy_registry_k3s</code></p></li><li><p>根据代理情况修改 <code>run.sh</code> 的前几行配置，默认创建 hub.docker.io, gcr.io, k8s-gcr.io 3个代理</p><p>如果要代理 <strong>hub.docker.io</strong> 请自行更换以下信息:</p><ul><li>UserName : <code>pod-hub-registry.yaml:72</code></li><li>Password: <code>pod-hub-registry.yaml:74</code></li></ul></li><li><p>运行: <code>./run.sh</code>，运行结束后会有如下输出表示相关仓库配置成功:</p></li></ol><pre><code class=language-shell>hub-k3s.io =&gt; HTTP/1.1 200 OK
gcr-k3s.io =&gt; HTTP/1.1 200 OK
k8s-gcr-k3s.io =&gt; HTTP/1.1 200 OK
</code></pre><ol start=5><li><p>使用 ansible 对自有 K3s 集群的所有节点配置代理</p><ul><li>记得在 <code>$ANSIBLE_INVENTORY</code> 中配置 k3s 相关 hosts</li><li>运行过程中，会询问 第一步 服务器的公网IP，填入即可</li></ul></li></ol><pre><code class=language-shell>ansible-playbook ansible-add-registry.yaml -K
</code></pre><ol start=6><li><strong>Enjoy it</strong></li></ol></blockquote><h2 id=搭建-k3s-单-master-集群>搭建 K3s 单 Master 集群</h2><p>相比使用 kubeadm 搭建 K8s 集群的复杂度而言，K3s 集群搭建是真的简单，仅一行命令:</p><pre><code class=language-shell># 创建 server
k3s-server # curl -sfL https://get.k3s.io | sh -

# 运行 worker 并加入 集群
k3s-workers # curl -sfL https://get.k3s.io | K3S_URL=https://k3s-server:6443 K3S_TOKEN=mynodetoken sh -
</code></pre><p>看起来如此简单，但当我将集群配置好开始运行 Pod 时，不同节点的 Pod 无论如何也不能互相访问，困扰了我好几天，最终我选择放弃研究（开始萌生退意了），打算不再使用官方的一键安装脚本，转而手动安装并使用 Wireguard 来做 flannel-backend。</p><blockquote><p>由于安装脚本较长，限于篇幅，可以在此 Github 仓库查看整理好的 Playbook，详见: <a href=https://github.com/eightpigs/k3s-ansible-playbooks>k3s-ansible-playbooks</a></p></blockquote><p>K3s 运行仅需要一个编译好的单文件，所以手动搭建过程主要分为2步:</p><ol><li>下载 k3s 二进制文件 && 安装 Wireguard</li><li>配置 Systemd</li></ol><pre><code class=language-yaml># 下载 k3s 二进制文件 &amp;&amp; 安装 Wireguard
- hosts: k3s
  remote_user: dev
  become: yes
  gather_facts: False
  tasks:
    - set_fact:
        k3s_version: &quot;v1.21.2+k3s1&quot;
        ip_link: ens18
    - name: Output K3s Version
      debug: msg=&quot;{{ k3s_version }}&quot;
      when: k3s_version is defined
    - name: Download K3s
      shell: |
        ls /usr/local/bin/k3s &gt; /dev/null 2&gt;&amp;1 || wget &quot;https://github.com/k3s-io/k3s/releases/download/{{ k3s_version }}/k3s&quot; -O /usr/local/bin/k3s
        chmod +x /usr/local/bin/k3s
      when: k3s_version is defined
    - name: Install Wireguard
      shell: |
        which wg &gt; /dev/null 2&gt;&amp;1 || apt install wireguard -y
</code></pre><p>以下仅是 k3s-server，k3s-workers 安装详见 Github 仓库: <a href=https://github.com/eightpigs/k3s-ansible-playbooks>k3s-ansible-playbooks</a></p><pre><code class=language-yaml># 配置 k3s-server Systemd
- hosts: k3s-master
  remote_user: dev
  become: yes
  gather_facts: False
  tasks:
    - name: Check K3s Server Installed
      shell: ls /etc/systemd/system/k3s.service &gt; /dev/null 2&gt;&amp;1 &amp;&amp; echo 1 || echo 0
      register: server_installed
    - name: Get IP
      shell: ip addr show {{ ip_link }} | grep inet | head -n 1 | awk '{print $2}' | sed -e 's/\/[0-9]\+//g'
      register: ip_addr
    - name: Output IP Addr
      debug: msg=&quot;IP {{ ip_addr.stdout }}; Installed {{ server_installed.stdout }}&quot;
      when: ip_addr is defined and ip_addr.rc == 0
    - name: Create K3s.service.env
      command: touch /etc/systemd/system/k3s.service.env
      when: server_installed is defined and server_installed.stdout == '0'
    - name: Create K3s Server System Unit
      when: ip_addr is defined and ip_addr.rc == 0 and server_installed is defined and server_installed.stdout == '0'
      shell: |
        cat &gt; /etc/systemd/system/k3s.service &lt;&lt;EOF
        [Unit]
        Description=Lightweight Kubernetes
        Documentation=https://k3s.io
        Wants=network-online.target

        [Install]
        WantedBy=multi-user.target

        [Service]
        Type=notify
        EnvironmentFile=/etc/systemd/system/k3s.service.env
        KillMode=process
        Delegate=yes
        # Having non-zero Limit*s causes performance problems due to accounting overhead
        # in the kernel. We recommend using cgroups to do container-local accounting.
        LimitNOFILE=1048576
        LimitNPROC=infinity
        LimitCORE=infinity
        TasksMax=infinity
        TimeoutStartSec=0
        Restart=always
        RestartSec=5s
        ExecStartPre=-/sbin/modprobe br_netfilter
        ExecStartPre=-/sbin/modprobe overlay
        ExecStart=/usr/local/bin/k3s \
            server \
            --tls-san {{ ip_addr.stdout }} \
            --node-ip {{ ip_addr.stdout }} \
            --node-external-ip {{ ip_addr.stdout }} \
            --no-deploy servicelb \
            --write-kubeconfig-mode=644 \
            --flannel-backend wireguard \
            --kube-proxy-arg &quot;proxy-mode=ipvs&quot; &quot;masquerade-all=true&quot; \
            --kube-proxy-arg &quot;metrics-bind-address=0.0.0.0&quot;
        EOF
    - name: Enable K3s Systemed
      command: systemctl enable k3s --now
      when: server_installed is defined and server_installed.stdout == '0'
    - name: get server token
      command: cat /var/lib/rancher/k3s/server/node-token
      register: server_token
    - name: output server token
      debug: msg=&quot;{{ server_token.stdout }}&quot;
      when: server_token is defined and server_token.rc == 0
</code></pre><p>安装完成后，可以使用 <code>kubectl get nodes -o wide</code> 查看所有节点信息</p><pre><code class=language-shell>NAME            STATUS   ROLES                  AGE   VERSION        INTERNAL-IP    EXTERNAL-IP   OS-IMAGE                       KERNEL-VERSION         CONTAINER-RUNTIME
k3s-worker-02   Ready    &lt;none&gt;                 46d   v1.21.2+k3s1   192.168.2.23   &lt;none&gt;        Debian GNU/Linux 10 (buster)   5.10.0-0.bpo.7-amd64   containerd://1.4.4-k3s2
k3s-master      Ready    control-plane,master   46d   v1.21.2+k3s1   192.168.2.21   &lt;none&gt;        Debian GNU/Linux 10 (buster)   5.10.0-0.bpo.7-amd64   containerd://1.4.4-k3s2
k3s-worker-01   Ready    &lt;none&gt;                 46d   v1.21.2+k3s1   192.168.2.22   &lt;none&gt;        Debian GNU/Linux 10 (buster)   5.10.0-0.bpo.7-amd64   containerd://1.4.4-k3s2
k3s-worker-03   Ready    &lt;none&gt;                 46d   v1.21.2+k3s1   192.168.2.24   &lt;none&gt;        Debian GNU/Linux 10 (buster)   5.10.0-0.bpo.7-amd64   containerd://1.4.4-k3s2
</code></pre><p>Next: <a href=https://eightpigs.io/2021/08/27/k3s_use_nfs/>K3s 上手 - NFS 存储配置</a></p><br><br><hr>文章作者：eightpigs<br>创作时间：2021-07-06<br>更新时间：2021-08-27<br>许可协议：<a href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank class=cc>CC by-nc-nd 4.0</a><hr></div><div class=footer><div class=copyright>&copy; 2014 -
2023
Eightpigs</div><div class=navbar><ul><li><a href=/>首页</a></li><li><a href=/archives>归档</a></li><li><a href=/pages/about>关于</a></li></ul></div></div><script type=text/javascript src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.0.1/highlight.min.js></script>
<script>hljs.initHighlightingOnLoad()</script><script type=text/javascript src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[','\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code', "sup"],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>